{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data\n",
    "\n",
    "Download sliced data from an online source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from pyplume.constants import FIELD_NETCDF_DIR\n",
    "from pyplume import dataloaders, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_span(delta):\n",
    "    # GMT, data recorded hourly\n",
    "    time_now = np.datetime64(\"now\", \"h\")\n",
    "    return (time_now - delta, time_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### format of region_data stuff\n",
    "\n",
    "(name, resolution, time range, lat range, lon range, expand range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### about tj_sample\n",
    "\n",
    "the purpose of tj_sample is a quick and dirty way to sample the thredds data from a bunch of different times to find out the positions of where data exists. data in close time ranges could all have the same holes in data, and we would never know if data was supposed to be there in the first place.\n",
    "\n",
    "so tj_sample is generated for the sole purpose of creating a mask showing where data shouldn't exist.\n",
    "\n",
    "## data masks\n",
    "\n",
    "where is there data? every timestep of HFR data is not always complete, so we need to know what nan points were supposed to have data and which ones were never meant to have data.\n",
    "\n",
    "A good way to find this out is to take several slices of data over a long period of time and check the coverage of each timestamp. This is the easiest way to kind of see the true coverage of HFR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_data = [\n",
    "    # {\n",
    "    #     \"name\": \"hurrhenri_hycom\",\n",
    "    #     \"url\": \"https://tds.hycom.org/thredds/dodsC/GLBy0.08/expt_93.0/uv3z\",\n",
    "    #     \"time_range\": (\"2021-08-21T12:00\", \"2021-08-23T18:00\"),\n",
    "    #     \"lat_range\": (38.162201, 41.520008),\n",
    "    #     \"lon_range\": (284.290368, 290.276249),\n",
    "    #     \"inclusive\": True,\n",
    "    #     \"u_key\": \"water_u\",\n",
    "    #     \"v_key\": \"water_v\",\n",
    "    #     \"drop_vars\": [\"tau\"]\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"hurrkay_2km\",\n",
    "        \"url\": \"http://hfrnet-tds.ucsd.edu/thredds/dodsC/HFR/USWC/2km/hourly/RTV/HFRADAR_US_West_Coast_2km_Resolution_Hourly_RTV_best.ncd\",\n",
    "        \"time_range\": [\"2022-09-08T06:00\", \"2022-09-12T00:00\"],\n",
    "        \"lat_range\": (32.11093, 32.73124),\n",
    "        \"lon_range\": (-118.565, -115.9924),\n",
    "        \"inclusive\": True,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"hurrkay_6km\",\n",
    "        \"url\": \"http://hfrnet-tds.ucsd.edu/thredds/dodsC/HFR/USWC/6km/hourly/RTV/HFRADAR_US_West_Coast_6km_Resolution_Hourly_RTV_best.ncd\",\n",
    "        \"time_range\": [\"2022-09-08T06:00\", \"2022-09-12T00:00\"],\n",
    "        \"lat_range\": (32.11093, 32.73124),\n",
    "        \"lon_range\": (-118.565, -115.9924),\n",
    "        \"inclusive\": True,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "save_dir = utils.get_dir(FIELD_NETCDF_DIR)\n",
    "regions = []\n",
    "for rd in region_data:\n",
    "    rd = copy.deepcopy(rd)\n",
    "    name = rd.pop(\"name\")\n",
    "    url = rd.pop(\"url\")\n",
    "    with dataloaders.DataLoader(url, **rd) as dl:\n",
    "        dl.save(save_dir / f\"{name}.nc\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('py3-parcels')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "0eba6c4b74a2f8ee4f11000f0a8df2ef42b87fd4ae75b12d527f1b8c08aad6c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
